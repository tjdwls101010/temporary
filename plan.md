# 내용
## 개요
- 반도체 웨이퍼 이상 탐지.
## EDA
- features는 총 1558개. 이들은 크게 3가지 구분 가능.
	- Features_1\~Features_3:
		- Features_1\~Features_2: 1~640까지의 정수형 변수.
			- Feature_1: 400이상의 이상치 제거.
			- Feature_2: 550이상의 이상치 제거.
	        - Features_3: 0~60까지의 실수형 변수.
			- Feature_3: 20이상의 이상치 제거.
	- Features_4\~Features_1558: 0이나 1로 이루어진 카테고리형 변수.
		- 이들 피처의 갯수가 너무 많고, 상관관계가 매우 높아 차원 축소(PCA 차원은 누적 분산 비율로 결정).
	- 랜덤으로 feature중 일부를 선택해가면서 그 분포를 확인하고, 이상치는 대략 제거.
- Target은 1개. 0:1=92%:8%.
	- 분포가 매우 불균형 하므로, 언더샘플링 or 오버샘플링.
## 모델링
- Logistic Regression
- Random Forest
- XGBoost
- LightGBM
- CatBoost
- Ensemble
- VotingClassifier
- AutoML(Pycaret)
---
---
# PPT
## Page.1
- 개요 설명
```대본
이번 발표에서는 반도체 웨이퍼의 이상 탐지 문제를 다룰 것입니다. 반도체는 매우 정밀한 공정을 요구하며, 작은 결함도 큰 문제를 초래할 수 있습니다. 이 문제를 해결하기 위해, 데이터 분석과 머신러닝 모델을 활용해 웨이퍼의 이상 여부를 예측하는 과정에 대해 설명드리겠습니다.
```
```스크립트
# 반도체 웨이퍼 이상 탐지 프로젝트

## 개요
- 목적: 데이터 분석과 머신러닝을 활용한 웨이퍼 이상 예측
- 중요성: 반도체 제조 공정의 정밀성과 품질 보장
- 접근 방법: 데이터 분석 → 모델 개발 → 이상 탐지

## 왜 중요한가?
- 작은 결함도 큰 문제 초래 가능
- 생산성 향상 및 비용 절감 효과
- 품질 관리의 자동화 및 효율화
```
---
## Page.2
- 데이터셋 설명
```대본
이 데이터셋은 반도체 웨이퍼의 상태를 나타내는 다양한 피처들로 구성되어 있으며, 총 1558개의 피처가 존재합니다. 각 피처는 반도체 제조 과정에서 수집된 다양한 센서 값들입니다. 이 피처들은 크게 세 그룹으로 나눌 수 있습니다: Features_1부터 Features_3, 그리고 Features_4부터 Features_1558입니다. 또한, 예측해야 하는 타겟 값(Target)은 웨이퍼의 이상 여부를 나타내며, 0(정상)과 1(이상)의 두 가지 값으로 이루어져 있습니다.
```
```스크립트
# 데이터셋 소개

## 구성
- 총 1558개의 피처
- 1개의 타겟 변수 (이상 여부)

## 피처 그룹
1. Features_1 ~ Features_3
   - 연속형 변수
   - 센서에서 수집된 수치 데이터

2. Features_4 ~ Features_1558
   - 카테고리형 변수 (0 또는 1)
   - 다양한 공정 상태 정보

## 타겟 변수
- 0: 정상 웨이퍼
- 1: 이상 웨이퍼
```
---
## Page.3
- 타겟 분포 확인
```대본
타겟 값의 분포를 보면, 0과 1의 비율이 92% 대 8%로 매우 불균형한 상태입니다. 이는 정상인 웨이퍼가 대다수이며, 이상이 있는 경우는 드물다는 것을 의미합니다. 이러한 불균형 문제를 해결하기 위해, 데이터를 언더샘플링하거나 오버샘플링하여 모델 학습 시 균형을 맞추도록 하였습니다.
```
```스크립트
# 타겟 변수 분포 분석

## 현재 상태
- 정상(0): 92%
- 이상(1): 8%

## 불균형 데이터의 특징
- 대다수가 정상 웨이퍼
- 이상 케이스는 소수

## 해결 방안
1. 언더샘플링
   - 다수 클래스 샘플 수 감소
2. 오버샘플링
   - 소수 클래스 샘플 수 증가
3. 가중치 조정
   - 모델 학습 시 클래스 가중치 부여
```
---
## Page.4
- 피처간 차이점 확인.
- 피처간 상관관계 시각화(Heatmap).
```대본
피처들은 다양한 값을 가지며, Features_1부터 Features_3는 연속적인 숫자로 이루어져 있고, Features_4부터 Features_1558는 0과 1의 값으로만 이루어진 카테고리형 데이터입니다. 피처 간의 상관관계를 확인하기 위해 Heatmap을 활용하여 시각화하였으며, 일부 피처들 간에는 높은 상관관계가 있음을 발견할 수 있었습니다. 이러한 상관관계를 이용해 차원 축소를 통해 데이터의 복잡성을 줄이는 작업을 진행했습니다.
```
```스크립트
# 피처 분석 및 상관관계

## 피처 유형
1. 연속형 변수 (Features_1 ~ Features_3)
   - 수치형 데이터
   - 센서 측정값

2. 카테고리형 변수 (Features_4 ~ Features_1558)
   - 이진 데이터 (0 또는 1)
   - 공정 상태 정보

## 상관관계 분석
- 히트맵 시각화 활용
- 주요 발견:
  - 일부 피처 간 높은 상관관계 존재
  - 차원 축소의 필요성 확인

## 차원 축소의 이점
- 데이터 복잡성 감소
- 모델 학습 속도 향상
- 과적합 위험 감소
```
---
## Page.5
- Features_continuous(Features_1~Features_3)의 시각화(Histplot) 및 타겟과의 상관관계 시각화(Boxplot, Scatterplot).
```대본
Features_1부터 Features_3까지의 연속형 피처들은 각각 히스토그램으로 시각화하였고, 이를 통해 데이터의 분포를 확인했습니다. 또한, 타겟 값과의 관계를 보기 위해 박스플롯과 산점도를 활용했습니다. 이를 통해 타겟 값에 따라 특정 피처들이 어떻게 변화하는지에 대한 힌트를 얻을 수 있었습니다.
```
```스크립트
# 연속형 변수 분석 (Features_1 ~ Features_3)

## 시각화 방법
1. 히스토그램
   - 각 피처의 분포 확인
2. 박스플롯
   - 타겟 변수에 따른 분포 비교
3. 산점도
   - 피처 간 관계 및 타겟과의 상관성 파악

## 주요 인사이트
- 분포의 특징 (정규분포, 치우침 등)
- 이상치 존재 여부
- 타겟 변수와의 관계성

## 활용 방안
- 특성 공학을 위한 기초 자료
- 모델 선택 및 하이퍼파라미터 튜닝 시 참고
```
---
## Page.6
- Features_continuous의 이상치 제거.
```대본
연속형 피처들 중에서는 일부 값들이 비정상적으로 높거나 낮은 경우가 있었습니다. 이러한 이상치들은 분석 결과에 영향을 줄 수 있기 때문에, Feature_1, Feature_2, Feature_3에서 특정 기준을 넘어서는 이상치들을 제거하였습니다.
```
```스크립트
# 연속형 변수 이상치 처리

## 이상치 정의
- 비정상적으로 높거나 낮은 값
- 통계적 기준 또는 도메인 지식 기반

## 이상치 제거 기준
- Feature_1: 400 이상 제거
- Feature_2: 550 이상 제거
- Feature_3: 20 이상 제거

## 이상치 처리의 중요성
1. 모델 성능 향상
2. 왜곡된 분석 결과 방지
3. 데이터 품질 개선

## 주의사항
- 무분별한 제거는 정보 손실 초래
- 도메인 전문가와의 협업 필요
```
---
## Page.7
- feaures_categorical(feature_4~Features_1558)에서 랜덤 피처를 선택한 후, 타겟별 분포 시각화(Pieplot).
```대본
Features_4부터 Features_1558까지는 0과 1로 이루어진 카테고리형 데이터입니다. 이들 중 몇 가지 피처를 무작위로 선택하여 타겟 값에 따른 분포를 파이 차트로 시각화하였습니다. 이를 통해 각 피처가 타겟 값과 어떤 관계를 가지는지 직관적으로 파악할 수 있었습니다.
```
```스크립트
# 카테고리형 변수 분석 (Features_4 ~ Features_1558)

## 분석 방법
- 랜덤 샘플링을 통한 대표 피처 선정
- 파이 차트를 활용한 타겟별 분포 시각화

## 시각화 목적
1. 각 피처의 클래스 분포 확인
2. 타겟 변수와의 관계성 파악
3. 유의미한 패턴 발견

## 인사이트 도출
- 특정 피처와 타겟 간 강한 연관성 확인
- 불필요하거나 중복되는 피처 식별
- 추가적인 특성 공학 방향 설정

## 다음 단계
- 중요 피처 선별
- 차원 축소 기법 적용 검토
```
---
## Page.8
- feaures_categorical의 PCA 차원 축소.
```대본
카테고리형 피처들은 개수가 많고, 상관관계가 높은 피처들이 많기 때문에, PCA(주성분 분석)를 활용해 차원을 축소했습니다. 이 과정은 피처의 수를 줄여 모델의 학습을 더 빠르고 효율적으로 만드는 데 도움을 줍니다. PCA 차원의 개수는 누적 분산 비율을 기준으로 결정하였습니다.
```
```스크립트
# 카테고리형 변수의 차원 축소 (PCA)

## PCA (주성분 분석) 개요
- 고차원 데이터를 저차원으로 변환
- 정보 손실 최소화하며 차원 축소

## PCA 적용 이유
1. 피처 수가 많음 (1555개)
2. 높은 상관관계 존재
3. 계산 효율성 향상 필요

## PCA 차원 결정 방법
- 누적 분산 비율 기준 사용
- 예: 95% 또는 99%의 분산 유지

## 기대 효과
1. 모델 학습 시간 단축
2. 과적합 위험 감소
3. 노이즈 제거 및 주요 패턴 강조
```
---
## Page.9
- 피처간 scale 통일을 위한 정규화.
```대본
각 피처의 값들이 서로 다른 범위를 가지기 때문에, 정규화를 통해 모든 피처들의 값을 동일한 범위로 맞추었습니다. 이는 머신러닝 모델이 특정 피처에 편향되지 않도록 하고, 전체적인 학습 성능을 향상시키는 데 중요한 과정입니다.
```
```스크립트
# 피처 스케일링

## 정규화의 필요성
- 서로 다른 범위를 가진 피처들 존재
- 스케일 차이로 인한 모델 편향 방지

## 적용 방법
1. 표준화 (StandardScaler)
   - 평균 0, 표준편차 1로 변환
   - 이상치에 덜 민감함
2. 장점
   - 정규 분포를 가정하는 알고리즘에 적합
   - 피처 간 상대적 크기 유지

## 스케일링의 이점
1. 모델의 수렴 속도 향상
2. 특정 피처에 대한 과도한 가중치 부여 방지
3. 다양한 알고리즘에 적용 가능

## 주의사항
- 테스트 데이터는 학습 데이터의 스케일링 파라미터 사용
- 이상치에 민감할 수 있으므로 사전 처리 필요
```
---
## Page.10
- 타겟값이 매우 불균형 하므로, Stratify를 적용한 data split.
```대본
데이터가 불균형하기 때문에, 모델 학습을 위해 데이터를 훈련용과 검증용으로 나눌 때 Stratify 기법을 사용했습니다. 이를 통해 각 데이터 분할에서 타겟 값의 분포가 원본 데이터와 유사하게 유지되도록 하여, 학습 과정에서 발생할 수 있는 편향을 최소화하였습니다.
```
```스크립트
# 데이터 분할 (Train-Test Split)

## Stratified Sampling 적용
- 불균형 데이터 처리를 위한 방법
- 각 부분집합에서 클래스 비율 유지

## 분할 비율
- 훈련 데이터: 80%
- 테스트 데이터: 20%

## Stratified Sampling의 장점
1. 편향된 학습 방지
2. 모델 성능의 일관성 유지
3. 과적합 위험 감소

## 검증 전략
- K-폴드 교차 검증 고려
- 홀드아웃 검증 세트 활용
```
---
## Page.11
- Logistic Regression 설명
```대본
로지스틱 회귀는 간단하지만 효과적인 이진 분류 알고리즘입니다. 이번 문제에서 로지스틱 회귀를 사용하여 웨이퍼의 이상 여부를 예측한 결과, 정확도는 다소 낮지만 기본적인 기준을 확인하는 데 사용되었습니다.
```
```스크립트
# 로지스틱 회귀 (Logistic Regression)

## 개요
- 이진 분류를 위한 기본적인 통계 모델
- 선형 결정 경계를 사용한 확률 기반 예측

## 특징
1. 해석 용이성
   - 각 피처의 영향력 파악 가능
2. 계산 효율성
   - 대규모 데이터셋에도 적용 가능
3. 과적합 위험 낮음
   - 단순한 모델 구조

## 한계점
- 복잡한 비선형 관계 포착 어려움
- 피처 간 상호작용 고려 제한적

## 활용
- 기준 모델(Baseline) 설정
- 초기 성능 평가 및 비교
```
---
## Page.12
- Logistic Regression 적용 및 결과 해석.
```대본

```
```스크립트
# 로지스틱 회귀 모델 적용 결과

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 모델의 장단점
   - 장점: 빠른 학습 및 예측 속도
   - 단점: 복잡한 패턴 포착 한계
2. 중요 피처 식별
   - 가장 영향력 있는 상위 5개 피처

## 개선 방향
- 비선형 관계를 고려한 특성 공학
- 앙상블 기법과의 결합 검토

## 다음 단계
- 더 복잡한 모델과의 성능 비교
- 하이퍼파라미터 튜닝을 통한 최적화
```
---
## Page.13
- Random Forest 설명
```대본
랜덤 포레스트는 여러 개의 의사결정 트리를 통해 예측을 수행하는 앙상블 기법입니다. 다양한 트리들이 예측을 보완함으로써, 보다 강건한 결과를 도출할 수 있었습니다.
```
```스크립트
# 랜덤 포레스트 (Random Forest)

## 개요
- 다수의 결정 트리를 결합한 앙상블 모델
- 배깅(Bagging)과 랜덤 피처 선택 활용

## 주요 특징
1. 높은 예측 성능
   - 다양한 트리의 집단 지성 활용
2. 과적합 저항성
   - 랜덤성을 통한 일반화 능력 향상
3. 피처 중요도 제공
   - 모델 해석에 유용한 정보 제공

## 작동 원리
1. 부트스트랩 샘플링
2. 랜덤 피처 선택
3. 개별 트리 학습
4. 다수결 투표 또는 평균

## 적용 분야
- 분류 및 회귀 문제
- 고차원 데이터 분석
```
---
## Page.14
- Random Forest 적용 및 결과 해석.
```대본

```
```스크립트
# 랜덤 포레스트 모델 적용 결과

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 로지스틱 회귀 대비 성능 향상
   - 비선형 관계 포착 능력 확인
2. 피처 중요도 분석
   - 상위 10개 중요 피처 식별

## 모델 특성
- 과적합 저항성 확인
- 예측 신뢰도 향상

## 최적화 방향
- 하이퍼파라미터 튜닝
  (트리 개수, 최대 깊이 등)
- 피처 선택을 통한 모델 간소화
```
---
## Page.15
- Boost(XGBoost, LGBMBoost, CatBoost) 설명
```대본
이 세 모델은 부스팅 계열의 앙상블 모델로, 각각 강력한 성능을 자랑합니다. XGBoost는 계산 속도와 효율성이 뛰어나고, LightGBM은 대규모 데이터셋에 유리하며, CatBoost는 카테고리형 데이터를 잘 다루는 특성을 가집니다.
```
```스크립트
# 부스팅 모델 소개

## 개요
- 약한 학습기를 순차적으로 결합
- 이전 모델의 오류를 보완하며 학습

## 주요 부스팅 알고리즘
1. XGBoost
   - 빠른 속도와 높은 성능
2. LightGBM
   - 대규모 데이터에 효율적
3. CatBoost
   - 범주형 변수 처리에 강점

## 공통 특징
- 높은 예측 정확도
- 과적합 방지 메커니즘
- 피처 중요도 제공

## 적용 시 고려사항
- 하이퍼파라미터 튜닝 중요
- 계산 비용이 상대적으로 높음
- 해석력은 다소 제한적
```
---
## Page.16
- XGBoost 적용 및 결과 해석.
```대본

```
```스크립트
# XGBoost 모델 적용 결과

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 이전 모델 대비 성능 향상
   - 복잡한 패턴 포착 능력 확인
2. 피처 중요도 분석
   - 상위 5개 중요 피처 및 해석

## 모델 특성
- 빠른 학습 및 예측 속도
- 과적합 방지 기능 효과

## 최적화 방향
- 학습률, 트리 깊이 등 튜닝
- 조기 종료(Early Stopping) 적용
```
---
## Page.17
- LightGBM 적용 및 결과 해석.
```대본

```
```스크립트
# LightGBM 모델 적용 결과

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 이전 모델 대비 성능 향상
   - 복잡한 패턴 포착 능력 확인
2. 피처 중요도 분석
   - 상위 5개 중요 피처 및 해석

## 모델 특성
- 빠른 학습 및 예측 속도
- 과적합 방지 기능 효과

## 최적화 방향
- 학습률, 트리 깊이 등 튜닝
- 조기 종료(Early Stopping) 적용
```
---
## Page.18
- CatBoost 적용 및 결과 해석.
```대본

```
```스크립트
# CatBoost 모델 적용 결과

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 이전 모델 대비 성능 향상
   - 복잡한 패턴 포착 능력 확인
2. 피처 중요도 분석
   - 상위 5개 중요 피처 및 해석

## 모델 특성
- 빠른 학습 및 예측 속도
- 과적합 방지 기능 효과

## 최적화 방향
- 학습률, 트리 깊이 등 튜닝
- 조기 종료(Early Stopping) 적용
```
---
## Page.19
- Ensemble(Logistic Regression, XGBoost, CatBoost) 적용 및 결과 해석.
```대본
로지스틱 회귀, XGBoost, CatBoost를 앙상블하여 VotingClassifier를 사용하였습니다. 이를 통해 다양한 모델들의 강점을 결합해 성능을 극대화할 수 있었습니다.
```
```스크립트
# 앙상블 모델 (Voting Classifier)

## 구성
- 로지스틱 회귀
- XGBoost
- CatBoost

## 앙상블 방식
- 소프트 보팅 (확률 평균)

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 개별 모델 대비 성능 향상
2. 예측 안정성 증가

## 장단점
- 장점: 다양한 모델의 강점 결합
- 단점: 계산 비용 증가, 해석 복잡성

## 향후 개선 방향
- 모델 가중치 최적화
- 스태킹(Stacking) 기법 고려
```
---
## Page.20
- AutoML(Pycaret) 설명
```대본
마지막으로, Pycaret을 활용한 AutoML을 통해 다양한 모델을 자동으로 비교하고 최적의 모델을 찾는 과정을 진행했습니다. 이를 통해 모델 선택 과정을 간소화하고, 효율적인 결과를 얻을 수 있었습니다.
```
```스크립트
# AutoML (Automated Machine Learning)

## 개요
- 머신러닝 파이프라인 자동화
- 데이터 전처리부터 모델 선택까지 최적화

## Pycaret 소개
- 파이썬 기반 오픈소스 AutoML 라이브러리
- 다양한 모델 비교 및 최적화 기능 제공

## AutoML의 장점
1. 시간 효율성
   - 수동 작업 대비 빠른 모델 개발
2. 광범위한 모델 탐색
   - 다양한 알고리즘 자동 비교
3. 초보자 친화적
   - 복잡한 ML 지식 없이도 사용 가능

## 주의사항
- 블랙박스 접근법 주의
- 도메인 지식의 중요성 간과 위험
```
---
## Page.21
- AutoML(Pycaret) 적용 및 결과 해석.
```대본

```
```스크립트
# AutoML (Pycaret) 적용 결과

## 최적 모델
- 선정된 최고 성능 모델: [모델명]

## 성능 지표
- 정확도 (Accuracy): X%
- 정밀도 (Precision): X%
- 재현율 (Recall): X%
- F1 점수: X

## 주요 인사이트
1. 수동 개발 모델과의 성능 비교
2. 효율적인 모델 탐색 및 최적화

## AutoML 프로세스 요약
1. 데이터 전처리
2. 피처 선택
3. 모델 비교 및 선정
4. 하이퍼파라미터 튜닝

## 향후 활용 방안
- 빠른 프로토타이핑 도구로 활용
- 수동 개발 모델의 벤치마크로 사용
```
---
